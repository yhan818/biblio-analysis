#institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2024-01-01",
to_publication_date = "2024-12-31",
#primary_location.source.type = "journal",
count_only = TRUE
)
library(openalexR)
packageVersion("openalexR")
library(here)
library(jsonlite)
library(dplyr)
library(tidyverse)
library(data.table)
library(openxlsx)
library(readxl)
library(writexl)
source("my_functions.R")
# free unused obj to manage memory
rm(list=ls())
gc()
options("max.print" = 100000)
options (openalexR.mailto="yhan@arizona.edu")
getwd()
print(here())
# Typically only some seconds
works_count <-oa_fetch(
entity="works",
#institutions.ror=c("03efmqc40"), # ASU
institutions.ror=c("05hs6h993"), # MSU
#institutions.ror=c("03m2x1q45"), # University of Arizona
#institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2024-01-01",
to_publication_date = "2024-12-31",
#primary_location.source.type = "journal",
count_only = TRUE
)
works_published_2024 <-oa_fetch(
entity="works",
# institutions.ror=c("03efmqc40"),  # ASU
institutions.ror=c("05hs6h993"), # MSU
# institutions.ror=c("03m2x1q45"), # U Arizona
# institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2024-01-01",
to_publication_date = "2024-12-31",
)
saveRDS(works_published_2024, "../msu_works_published_2024.rds")
works_published <- works_published_2024
####################################################
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
works_published_ref <- works_published$referenced_works
# There are NA references. So we need to remove them.
# No references: 20% (2022), 14% (2021)
# This na_indices include type: article, books, errata, letter, and other types
na_indices <- which(sapply(works_published_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(works_published_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(works_published_ref) * 100
# Remove duplicate rows from the data frame
unique_works_published <- unique(works_published)
works_published_ref <- unique(works_published_ref) # this actually also remove NA lists.
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- works_published %>%
filter(is.na(referenced_works) & type == "article")
# rm(works_published_ref_combined)
works_published_ref_combined <- unlist(works_published_ref, use.names = FALSE)
works_published_ref_combined <- works_published_ref_combined[!is.na(works_published_ref_combined)]  # Remove NA values
#########################
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
works_cited2 <-data.frame()
fetch_number <- 50
num_of_works <- length (works_published_ref_combined)
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
batch_identifiers <- works_published_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
# Have to use "primary_location.source.type = journal" to filter out non-journal.
# issn_l cannot be used alone (there are book chapters which have issn per OpenAlex)
oa_fetch(identifier = batch_identifiers)
#, primary_location.source.type = "journal")
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data) && nrow(batch_data) >0 ) {
# Ensure consistent columns
batch_data <- data.table::setDT(batch_data)[, setdiff(names(works_cited), names(batch_data)) := NA]
works_cited <- rbindlist(list(works_cited, batch_data), use.names = TRUE, fill = TRUE)
}
}
}
})
print(time_taken)
# 2024-04-04:
#  UA: 2024: 305,670
# ASU: 2024: 271,694
# MSU: 2024:
# UW:  2024: 616,427
saveRDS(works_cited, "../msu_works_cited_2024.rds")
# Typically only some seconds
works_count <-oa_fetch(
entity="works",
#institutions.ror=c("03efmqc40"), # ASU
institutions.ror=c("05hs6h993"), # MSU
#institutions.ror=c("03m2x1q45"), # University of Arizona
#institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2023-01-01",
to_publication_date = "2023-12-31",
#primary_location.source.type = "journal",
count_only = TRUE
)
# Typically only some seconds
works_count <-oa_fetch(
entity="works",
#institutions.ror=c("03efmqc40"), # ASU
institutions.ror=c("05hs6h993"), # MSU
#institutions.ror=c("03m2x1q45"), # University of Arizona
#institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2023-01-01",
to_publication_date = "2023-12-31",
#primary_location.source.type = "journal",
count_only = TRUE
)
works_published_2023 <-oa_fetch(
entity="works",
# institutions.ror=c("03efmqc40"),  # ASU
institutions.ror=c("05hs6h993"), # MSU
# institutions.ror=c("03m2x1q45"), # U Arizona
# institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2023-01-01",
to_publication_date = "2023-12-31",
)
saveRDS(works_published_2023, "../msu_works_published_2023.rds")
# to filter "journal" works only. I feel it shall not be this restrict. (other works like grey literature are good too)
works_published <- works_published_2023
####################################################
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
works_published_ref <- works_published$referenced_works
# There are NA references. So we need to remove them.
# No references: 20% (2022), 14% (2021)
# This na_indices include type: article, books, errata, letter, and other types
na_indices <- which(sapply(works_published_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(works_published_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(works_published_ref) * 100
# Remove duplicate rows from the data frame
unique_works_published <- unique(works_published)
works_published_ref <- unique(works_published_ref) # this actually also remove NA lists.
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- works_published %>%
filter(is.na(referenced_works) & type == "article")
# rm(works_published_ref_combined)
works_published_ref_combined <- unlist(works_published_ref, use.names = FALSE)
works_published_ref_combined <- works_published_ref_combined[!is.na(works_published_ref_combined)]  # Remove NA values
works_cited_2024 <-works_cited
#########################
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
works_cited2 <-data.frame()
fetch_number <- 50
num_of_works <- length (works_published_ref_combined)
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
batch_identifiers <- works_published_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
# Have to use "primary_location.source.type = journal" to filter out non-journal.
# issn_l cannot be used alone (there are book chapters which have issn per OpenAlex)
oa_fetch(identifier = batch_identifiers)
#, primary_location.source.type = "journal")
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data) && nrow(batch_data) >0 ) {
# Ensure consistent columns
batch_data <- data.table::setDT(batch_data)[, setdiff(names(works_cited), names(batch_data)) := NA]
works_cited <- rbindlist(list(works_cited, batch_data), use.names = TRUE, fill = TRUE)
}
}
}
})
print(time_taken)
# UA:  2023: 353,424
# ASU: 2023: 317,643
# MSU: 2023:
# UW:  2023: 706,551
saveRDS(works_cited, "../msu_works_cited_2023.rds")
# Typically only some seconds
works_count <-oa_fetch(
entity="works",
#institutions.ror=c("03efmqc40"), # ASU
institutions.ror=c("05hs6h993"), # MSU
#institutions.ror=c("03m2x1q45"), # University of Arizona
#institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2022-01-01",
to_publication_date = "2022-12-31",
#primary_location.source.type = "journal",
count_only = TRUE
)
works_published_2022 <-oa_fetch(
entity="works",
# institutions.ror=c("03efmqc40"),  # ASU
# institutions.ror=c("03m2x1q45"), # UArizona
institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2022-01-01",
to_publication_date = "2022-12-31",
)
works_published_2022 <-oa_fetch(
entity="works",
# institutions.ror=c("03efmqc40"),  # ASU
institutions.ror=c("05hs6h993"), # MSU
# institutions.ror=c("03m2x1q45"), # U Arizona
# institutions.ror=c("00cvxb145"), # University of Washington
from_publication_date ="2022-01-01",
to_publication_date = "2022-12-31",
)
saveRDS(works_published_2022, "../msu_works_published_2022.rds")
works_published <- works_published_2022
####################################################
##### 2. Checking and verifying data
##### 2.1 Route 1: Getting citation data from $referenced_works
##### Route 2: Getting author's data?
###### change this line only to update the right dataset.
works_published_ref <- works_published$referenced_works
# There are NA references. So we need to remove them.
# No references: 20% (2022), 14% (2021)
# This na_indices include type: article, books, errata, letter, and other types
na_indices <- which(sapply(works_published_ref, function(x) is.logical(x) && is.na(x)))
na_count <- sum(sapply(works_published_ref, function(x) is.logical(x) && is.na(x)))
na_percent <- na_count/length(works_published_ref) * 100
# Remove duplicate rows from the data frame
unique_works_published <- unique(works_published)
works_published_ref <- unique(works_published_ref) # this actually also remove NA lists.
# Filter the rows where $reference_works is NA and $type is "article"
works_na_referenced_works <- works_published %>%
filter(is.na(referenced_works) & type == "article")
# rm(works_published_ref_combined)
works_published_ref_combined <- unlist(works_published_ref, use.names = FALSE)
works_published_ref_combined <- works_published_ref_combined[!is.na(works_published_ref_combined)]  # Remove NA values
works_cited_2023 <-works_cited
#########################
# Ensure oa_fetch() is receiving the correct input and create a new dataframe for results.
works_cited <- data.frame()
works_cited2 <-data.frame()
fetch_number <- 50
num_of_works <- length (works_published_ref_combined)
# Loop to fetch data in batches
time_taken <- system.time({
for(i in seq(1, num_of_works, by = fetch_number)) {
batch_identifiers <- works_published_ref_combined[i:min(i + fetch_number - 1, num_of_works)]
# Check if the batch_identifiers is a valid vector
if (length(batch_identifiers) > 0 && !all(is.na(batch_identifiers))) {
# Fetch data from OpenAlex using oa_fetch, ensure proper identifier input
batch_data <- tryCatch({
# Have to use "primary_location.source.type = journal" to filter out non-journal.
# issn_l cannot be used alone (there are book chapters which have issn per OpenAlex)
oa_fetch(identifier = batch_identifiers)
#, primary_location.source.type = "journal")
}, error = function(e) {
message("Error fetching data: ", e)
return(NULL)
})
# Only bind non-null data
if (!is.null(batch_data) && nrow(batch_data) >0 ) {
# Ensure consistent columns
batch_data <- data.table::setDT(batch_data)[, setdiff(names(works_cited), names(batch_data)) := NA]
works_cited <- rbindlist(list(works_cited, batch_data), use.names = TRUE, fill = TRUE)
}
}
}
})
print(time_taken)
# UA:  2022: 342,918
# ASU: 2022: 303,563
# MSU: 2022:
# UW:  2022: 678,317
saveRDS(works_cited, "../msu_works_cited_2022.rds")
works_cited <- works_cited_2022 %>%
mutate(authored_year = 2022) %>%
select(authored_year, everything())  # This moves UA_authored_year to first position
works_cited <- works_cited %>%
mutate(authored_year = 2022) %>%
select(authored_year, everything())  # This moves UA_authored_year to first position
works_cited_type_articles    <- subset(works_cited, type == "article")
unique(works_cited_type_articles$type)
unique_issns <- unique(works_cited_type_articles$issn_l)
number_of_unique_issns <- length(unique_issns)
publisher_str <- "Springer Nature"
works_cited_type_articles_sn <- works_cited_type_articles %>%
filter(grepl(publisher_str, host_organization_name, ignore.case = TRUE))
works_cited_type_nonarticles_sn <- works_cited_type_nonarticles %>%
filter(grepl(publisher_str, host_organization, ignore.case = TRUE))
works_published_sn <- works_published %>%
filter(grepl(publisher_str, host_organization, ignore.case = TRUE))
works_cited_type_articles_sn_22 <- works_cited_type_articles_sn
publisher_str <- "Nature Portfolio"
works_cited_type_articles_nature <- works_cited_type_articles %>%
filter(tolower(host_organization_name) == tolower(publisher_str))
works_cited_type_articles_nature_22 <- works_cited_type_articles_nature
#### 2025-04: Springer Nature: there are two publishers "Springer Nature" and "Springer Nature (Netherland) :
# 2022: MSU: 3,648; UArizona: 2,686 ; U Washington: 6,950;
# 2023: MSU: UArizona: 3,118; U Washington: 8,189;
# 2024: MSU: UArizona: 2,550; U Washington: 6,787
rm(works_cited)
works_cited <-works_cited_2023
publisher_str <- "Springer Nature"
works_cited_type_articles_sn <- works_cited_type_articles %>%
filter(grepl(publisher_str, host_organization_name, ignore.case = TRUE))
publisher_str <- "Springer Nature"
works_cited_type_articles_sn <- works_cited_type_articles %>%
filter(grepl(publisher_str, host_organization_name, ignore.case = TRUE))
works_cited_type_nonarticles_sn <- works_cited_type_nonarticles %>%
filter(grepl(publisher_str, host_organization, ignore.case = TRUE))
works_cited <- works_cited %>%
mutate(authored_year = 2023) %>%
select(authored_year, everything())  # This moves UA_authored_year to first position
works_cited_type_articles    <- subset(works_cited, type == "article")
unique(works_cited_type_articles$type)
unique_issns <- unique(works_cited_type_articles$issn_l)
number_of_unique_issns <- length(unique_issns)
works_cited_type_nonarticles <- subset(works_cited, type != "article")
unique(works_cited_type_nonarticles$type)
unique_issns2 <- unique(works_cited_type_nonarticles$issn_l)
number_of_unique_issns2 <- length(unique_issns2)
works_cited_type_articles_sn <- works_cited_type_articles %>%
filter(grepl(publisher_str, host_organization_name, ignore.case = TRUE))
works_cited_type_nonarticles_sn <- works_cited_type_nonarticles %>%
filter(grepl(publisher_str, host_organization, ignore.case = TRUE))
# Since there are two publishers: use "grepl"
#works_cited_type_articles_sn <- works_cited_type_articles %>%  filter(tolower(host_organization) == tolower(publisher_str))
rm(works_cited_type_articles_sn)
works_cited_type_articles_sn <- works_cited_type_articles %>%
filter(grepl(publisher_str, host_organization_name, ignore.case = TRUE))
works_cited_type_articles_sn_23 <- works_cited_type_articles_sn
publisher_str <- "Nature Portfolio"
works_cited_type_articles_nature <- works_cited_type_articles %>%
filter(tolower(host_organization_name) == tolower(publisher_str))
rm(works_cited)
works_cited <- works_cited_2024
rm(works_cited)
works_cited <- works_cited_2024 %>%
mutate(authored_year = 2024) %>%
select(authored_year, everything())  # This moves UA_authored_year to first position
works_cited_type_articles    <- subset(works_cited, type == "article")
unique(works_cited_type_articles$type)
unique_issns <- unique(works_cited_type_articles$issn_l)
number_of_unique_issns <- length(unique_issns)
works_cited_type_nonarticles <- subset(works_cited, type != "article")
unique(works_cited_type_nonarticles$type)
unique_issns2 <- unique(works_cited_type_nonarticles$issn_l)
number_of_unique_issns2 <- length(unique_issns2)
publisher_str <- "Springer Nature"
works_cited_type_articles_nature_23 <- works_cited_type_articles_nature
# Since there are two publishers: use "grepl"
#works_cited_type_articles_sn <- works_cited_type_articles %>%  filter(tolower(host_organization) == tolower(publisher_str))
rm(works_cited_type_articles_sn)
works_cited_type_articles_sn <- works_cited_type_articles %>%
filter(grepl(publisher_str, host_organization_name, ignore.case = TRUE))
works_cited_type_articles_sn_24 <- works_cited_type_articles_sn
works_cited_type_articles_sn_22_23_24 <- bind_rows(works_cited_type_articles_sn_22,
works_cited_type_articles_sn_23,
works_cited_type_articles_sn_24)
saveRDS(works_cited_type_articles_sn_22_23_24, "./citations/uw_works_cited_type_articles_sn_22_23_24.rds")
works_cited_type_articles_sn_yr22_23_24 <- extract_topics_by_level(works_cited_type_articles_sn_23_24, 1)
source("my_functions.R")
works_cited_type_articles_sn_yr22_23_24 <- extract_topics_by_level(works_cited_type_articles_sn_23_24, 1)
Q
Q
Q
Q
Q
actual_df <- "works_cited_type_articles_sn_22_23_24"
if (exists(actual_df) && is.data.frame(get(actual_df))) {
df <- get(actual_df)
rds_file_name <- paste0("uw_", actual_df, ".rds")
rds_file_path <- file.path("./citations", rds_file_name)
saveRDS(df, rds_file_path)
df_processed <- extract_topics_by_level(df, 1)
write_df_to_excel(df_processed)
} else {
if (!exists(actual_df)) {
print(paste("Error: Data frame '", actual_df, "' does not exist. Skipping operations.", sep=""))
} else {
print(paste("Error: Object '", actual_df, "' exists but is not a data frame. Skipping operations.", sep=""))
}
}
publisher_str <- "Nature Portfolio"
works_cited_type_articles_nature <- works_cited_type_articles %>%
filter(tolower(host_organization_name) == tolower(publisher_str))
works_cited_type_articles_nature_24 <- works_cited_type_articles_nature
works_cited_type_articles_nature_22_23_24 <- bind_rows(works_cited_type_articles_nature_22,
works_cited_type_articles_nature_23,
works_cited_type_articles_nature_24)
actual_df <- "works_cited_type_articles_nature_22_23_24"
if (exists(actual_df) && is.data.frame(get(actual_df))) {
df <- get(actual_df)
rds_file_name <- paste0("msu_", actual_df, ".rds")  # change institution name here
rds_file_path <- file.path("./citations", rds_file_name)
saveRDS(df, rds_file_path)
df_processed <- extract_topics_by_level(df, 1)
} else {
if (!exists(actual_df)) {
print(paste("Error: Data frame '", actual_df, "' does not exist. Skipping operations.", sep=""))
} else {
print(paste("Error: Object '", actual_df, "' exists but is not a data frame. Skipping operations.", sep=""))
}
}
write_df_to_excel(works_cited_type_articles_nature_yr22_23_24)
write_df_to_excel(df_processed)
### Binding Springer Nature and Nature together
works_cited_type_articles_nature_sn_yr22_23_24 <-bind_rows(works_cited_type_articles_nature_yr22_23_24, works_cited_type_articles_sn_yr22_23_24)
### Binding Springer Nature and Nature together
works_cited_type_articles_nature_yr22_23_24 <-df_processed
works_cited_type_articles_nature_sn_yr22_23_24 <-bind_rows(works_cited_type_articles_nature_yr22_23_24, works_cited_type_articles_sn_yr22_23_24)
actual_df <- "works_cited_type_articles_sn_22_23_24"
if (exists(actual_df) && is.data.frame(get(actual_df))) {
df <- get(actual_df)
rds_file_name <- paste0("uw_", actual_df, ".rds")
rds_file_path <- file.path("./citations", rds_file_name)
saveRDS(df, rds_file_path)
df_processed2 <- extract_topics_by_level(df, 1)
works_cited_type_articles_nature_yr22_23_24 <- df_processed2
} else {
if (!exists(actual_df)) {
print(paste("Error: Data frame '", actual_df, "' does not exist. Skipping operations.", sep=""))
} else {
print(paste("Error: Object '", actual_df, "' exists but is not a data frame. Skipping operations.", sep=""))
}
}
actual_df <- "works_cited_type_articles_sn_22_23_24"
if (exists(actual_df) && is.data.frame(get(actual_df))) {
df <- get(actual_df)
rds_file_name <- paste0("msu_", actual_df, ".rds")
rds_file_path <- file.path("./citations", rds_file_name)
saveRDS(df, rds_file_path)
df_processed2 <- extract_topics_by_level(df, 1)
works_cited_type_articles_sn_yr22_23_24 <- df_processed2
} else {
if (!exists(actual_df)) {
print(paste("Error: Data frame '", actual_df, "' does not exist. Skipping operations.", sep=""))
} else {
print(paste("Error: Object '", actual_df, "' exists but is not a data frame. Skipping operations.", sep=""))
}
}
### Binding Springer Nature and Nature together
works_cited_type_articles_nature_yr22_23_24 <-df_processed
works_cited_type_articles_nature_sn_yr22_23_24 <-bind_rows(works_cited_type_articles_nature_yr22_23_24, works_cited_type_articles_sn_yr22_23_24)
write_df_to_excel(works_cited_type_articles_nature_sn_yr22_23_24)
df <- works_cited_type_articles_nature_sn_yr22_23_24
required_columns <- c("source_display_name", "issn_l", "host_organization_name")
columns_exist <- required_columns %in% colnames(df)
# 2025-05: new
top_cited_journals <- rank_top_cited_journals(works_cited_type_articles_nature_sn_yr22_23_24, "source_display_name", "issn_l", "host_organization_name", 3000)
# Combine Excel Files
excel_files <- c("citations/msu_works_cited_type_articles_nature_sn_yr22_23_24.xlsx", "citations/msu_nature_sn_yr22_23_24_top_cited_j.xlsx", "citations/README.xlsx")
tryCatch({
wb <- createWorkbook()
for (i in seq_along(excel_files)) {
df <- read.xlsx(excel_files[i])
sheet_name <- gsub("citations/(.*)\\.xlsx", "\\1", excel_files[i]) # Extract sheet name from file name
sheet_name <-substr(sheet_name, 1, 31)  # Truncate to 31 chars for worksheet
addWorksheet(wb, sheetName = sheet_name)
writeData(wb, sheet = sheet_name, x = df)
}
saveWorkbook(wb, "citations/msu_works_cited_type_articles_nature_sn_yr22_23_24_v2.xlsx", overwrite = TRUE)
message("!!! Combination successful!")
}, error = function(e) {
message("Combination failed: ", e)
print(e)
})
ua_df <- readxl::read_excel("citations/nature_sn_yr22_23_24_top_cited_j.xlsx")
# ou_df <-readxl::read_excel("citations/asu_nature_sn_yr22_23_24_top_cited_j.xlsx")
ou_df <-readxl::read_excel("citations/msu_nature_sn_yr22_23_24_top_cited_j.xlsx")
# Compare top 10
comparison <- compare_top_journals(ua_df, ou_df, 10)
print("--- Top 10 Journal Comparison ---")
print(paste("Common Journals:", paste(comparison$common, collapse = ", ")))
print(paste("UA Unique Journals:", paste(comparison$ua_unique, collapse = ", ")))
print(paste("U Unique Journals:", paste(comparison$ou_unique, collapse = ", ")))
print(paste("Number of Common Journals:", comparison$count_common))
print(paste("Number of UA Unique Journals:", comparison$count_ua_unique))
print(paste("Number of U Unique Journals:", comparison$count_ou_unique))
# Compare top 100
comparison <- compare_top_journals(ua_df, ou_df, 100)
print("--- Top 100 Journal Comparison ---")
print(paste("Common Journals:", paste(comparison$common, collapse = ", ")))
print(paste("UA Unique Journals:", paste(comparison$ua_unique, collapse = ", ")))
print(paste("U Unique Journals:", paste(comparison$ou_unique, collapse = ", ")))
print(paste("Number of Common Journals:", comparison$count_common))
print(paste("Number of UA Unique Journals:", comparison$count_ua_unique))
print(paste("Number of U Unique Journals:", comparison$count_ou_unique))
View(works_cited_type_articles_nature_23)
work_cited<-"https://openalex.org/W1494075612"
find_org_works(work_cited, works_published_2023)
find_org_works(work_cited, works_published_2024)
View(works_cited_type_articles_nature_24)
find_org_works(work_cited, works_published_2022)
View(works_cited_type_articles_nature_22)
